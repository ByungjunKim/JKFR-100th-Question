{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP8LSEvVhdg7g5ftmjrx2Ow",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ByungjunKim/JKFR-100th-Question/blob/main/Author_id(KAC)_%EB%A7%A4%EC%B9%AD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1PfQ7jdSrbN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e695518-c6a5-4188-c241-38ef9ce34366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: thefuzz in /usr/local/lib/python3.12/dist-packages (0.22.1)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.12/dist-packages (0.27.3)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from thefuzz) (3.14.3)\n",
            "Requirement already satisfied: Levenshtein==0.27.3 in /usr/local/lib/python3.12/dist-packages (from python-Levenshtein) (0.27.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install thefuzz python-Levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from rapidfuzz import process, fuzz, utils\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
        "csv_file = '/content/[í˜„ëŒ€ì†Œì„¤ì—°êµ¬ ë²ˆì—­ì„œ, ì›ì„œ ì°¸ê³ ë¬¸í—Œ ìµœì¢…] (ë…¼ë¬¸ ë°œí–‰ì—°ë„ í¬í•¨).csv'\n",
        "json_file = '/content/Person_slim_all (1).json'\n",
        "\n",
        "# 2. ë°ì´í„° ë¡œë“œ\n",
        "df = pd.read_csv(csv_file)\n",
        "with open(json_file, 'r', encoding='utf-8') as f:\n",
        "    json_data = json.load(f)\n",
        "\n",
        "df['ì œì–´ë²ˆí˜¸'] = None\n",
        "df['ë§¤ì¹­ì ìˆ˜'] = 0.0 # Initialize as float to prevent FutureWarning\n",
        "\n",
        "# 3. í—¬í¼ í•¨ìˆ˜: ë‹¤ì–‘í•œ íƒ€ì…ì„ ë¬¸ìì—´ë¡œ í†µì¼\n",
        "def extract_name_string(name_data):\n",
        "    if isinstance(name_data, str): return name_data.strip()\n",
        "    if isinstance(name_data, dict): return name_data.get('label') or name_data.get('value') or str(name_data)\n",
        "    if isinstance(name_data, list): return extract_name_string(name_data[0]) if name_data else \"\"\n",
        "    return str(name_data) if name_data else \"\"\n",
        "\n",
        "# 4. JSON ë°ì´í„° ìƒ‰ì¸ (label + altlabel í¬í•¨)\n",
        "print(\"LOD DB ìƒ‰ì¸ ì¤‘ (ì•½ 100ë§Œ ê±´)...\")\n",
        "name_to_id_map = {}\n",
        "for item in json_data:\n",
        "    target_id = item.get('id')\n",
        "    candidates = [extract_name_string(item.get('label'))]\n",
        "    alts = item.get('altlabel') or item.get('alterlabel') or []\n",
        "    if isinstance(alts, list):\n",
        "        candidates.extend([extract_name_string(a) for a in alts])\n",
        "    else:\n",
        "        candidates.append(extract_name_string(alts))\n",
        "\n",
        "    for name in set(filter(None, candidates)):\n",
        "        name_to_id_map[name] = target_id\n",
        "\n",
        "lookup_names = list(name_to_id_map.keys())\n",
        "\n",
        "# 5. ë§¤ì¹­ í•¨ìˆ˜ (RapidFuzz ê¸°ë°˜)\n",
        "def perform_rapid_match(name):\n",
        "    if pd.isna(name) or str(name).strip() == '':\n",
        "        return None, 0\n",
        "\n",
        "    # 100ë§Œ ê±´ ëŒ€ì¡°ë¥¼ ìœ„í•´ score_cutoff ì„¤ì • (ì—°ì‚° ì ˆì•½)\n",
        "    result = process.extractOne(\n",
        "        str(name),\n",
        "        lookup_names,\n",
        "        scorer=fuzz.token_sort_ratio,\n",
        "        processor=utils.default_process,\n",
        "        score_cutoff=60  # ìµœì†Œ 60ì  ì´ìƒë§Œ í›„ë³´ë¡œ ê³ ë ¤\n",
        "    )\n",
        "\n",
        "    if result:\n",
        "        matched_name, score, _ = result\n",
        "        return name_to_id_map.get(matched_name), score\n",
        "    return None, 0\n",
        "\n",
        "# 6. ì‹¤í–‰ (ìºì‹± í™œìš©ìœ¼ë¡œ ìœ ë‹ˆí¬ ì‘ê°€ë§Œ ê³„ì‚°)\n",
        "print(\"ğŸš€ ë§¤ì¹­ ì‹œì‘ (100ë§Œ ê±´ ëŒ€ìƒ)...\")\n",
        "unique_authors = df['author_ì •ì œ'].dropna().unique()\n",
        "match_cache = {}\n",
        "\n",
        "for name in tqdm(unique_authors, desc=\"ì‘ê°€ëª… ë§¤ì¹­ ì¤‘\"):\n",
        "    match_cache[name] = perform_rapid_match(name)\n",
        "\n",
        "# 7. ê²°ê³¼ ë°˜ì˜ ë° í•„í„°ë§ (85ì  ê¸°ì¤€)\n",
        "df['match_res'] = df['author_ì •ì œ'].map(match_cache)\n",
        "df['temp_id'] = df['match_res'].apply(lambda x: x[0] if isinstance(x, tuple) else None)\n",
        "df['temp_score'] = df['match_res'].apply(lambda x: x[1] if isinstance(x, tuple) else 0.0) # Ensure 0 is float\n",
        "\n",
        "# [ì¡°ê±´ ì ìš©] 85ì  ì´ìƒë§Œ ì œì–´ë²ˆí˜¸ì™€ ì ìˆ˜ë¥¼ í™•ì • ê¸°ë¡\n",
        "confirm_mask = df['temp_score'] >= 85\n",
        "df.loc[confirm_mask, 'ì œì–´ë²ˆí˜¸'] = df.loc[confirm_mask, 'temp_id']\n",
        "df.loc[confirm_mask, 'ë§¤ì¹­ì ìˆ˜'] = df.loc[confirm_mask, 'temp_score']\n",
        "\n",
        "# 8. ë¯¸ê²€ìˆ˜ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ (85ì  ë¯¸ë§Œ ë˜ëŠ” ë§¤ì¹­ ì‹¤íŒ¨)\n",
        "# ì œì–´ë²ˆí˜¸ê°€ ë¹„ì–´ìˆëŠ” ëª¨ë“  ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
        "unverified_df = df[df['ì œì–´ë²ˆí˜¸'].isna()][['author_ì •ì œ', 'title_ì •ì œ', 'temp_id', 'temp_score']].copy()\n",
        "unverified_df.columns = ['ì‘ê°€ëª…_ì •ì œ', 'ì‘í’ˆëª…_ì •ì œ', 'ì¶”ì²œ_id', 'ìœ ì‚¬ë„ì ìˆ˜']\n",
        "\n",
        "# 9. íŒŒì¼ ì €ì¥\n",
        "# ìµœì¢… ê²°ê³¼ íŒŒì¼ (ì„ì‹œ ì»¬ëŸ¼ ì œì™¸)\n",
        "df.drop(columns=['match_res', 'temp_id', 'temp_score']).to_csv('result_step1.csv', index=False, encoding='utf-8-sig')\n",
        "# ë¯¸ê²€ìˆ˜ ë¦¬ìŠ¤íŠ¸ ì €ì¥\n",
        "unverified_df.to_csv('ë¯¸ê²€ìˆ˜_ì‘ê°€_ë¦¬ìŠ¤íŠ¸.csv', index=False, encoding='utf-8-sig')\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(f\"âœ… ì‘ì—… ì™„ë£Œ!\")\n",
        "print(f\" - ìë™ ë§¤ì¹­ ì„±ê³µ (85ì  ì´ìƒ): {confirm_mask.sum():,} ê±´\")\n",
        "print(f\" - ë¯¸ê²€ìˆ˜ ë¦¬ìŠ¤íŠ¸ ìƒì„±: {len(unverified_df):,} ê±´\")\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "KGXn-QJTtZaj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}